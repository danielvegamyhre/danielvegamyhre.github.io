---
layout: post
title:  "EleutherAI ML Perf Reading Group: Zero Bubble Pipeline Parallelism"
date:   2025-02-09 12:45:51 -0700
categories: ml performance
---

For session 6 of the Eleuther AI ML Scalability & Performance reading group, I gave a presentation covering Zero Bubble Pipeline Parallelism. I also covered 2 key pieces of prior work which provide context, to understand what the limitations were of those prior approaches and put the innovations of Zero Bubble PP in context.

My annotated versions of these papers can be found be found on my Github [here](https://github.com/danielvegamyhre/ml-scalability-and-performance-reading-group/tree/main/session_6).


Papers:
1. [GPipe: Easy Scaling with Micro-Batch Pipeline Parallelism](https://arxiv.org/abs/1811.06965)
2. [PipeDream: Fast and Efficient Pipeline Parallel DNN Training](https://arxiv.org/abs/1806.03377)
3. [Zero Bubble Pipeline Parallelism](https://arxiv.org/abs/2401.10241)

Note: you may have to disable ad blocker for the YouTube player to render correctly. Alternatively, you can watch the recording directly on YouTube [here](https://www.youtube.com/watch?v=4wTuGkiob7o).

<iframe width="560" height="315" src="https://www.youtube.com/embed/4wTuGkiob7o?si=iS65BAFxRwqroAHY" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" referrerpolicy="strict-origin-when-cross-origin" allowfullscreen></iframe>