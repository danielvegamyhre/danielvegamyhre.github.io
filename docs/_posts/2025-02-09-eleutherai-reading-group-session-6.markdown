---
layout: post
title:  "Zero Bubble Pipeline Parallelism"
date:   2025-02-09 12:45:51 -0700
categories: ml performance
---

For session 6 of the Eleuther AI ML Scalability & Performance reading group, I gave a presentation covering Zero Bubble Pipeline Parallelism. I also covered 2 key pieces of prior work which provide context, to understand what the limitations were of those prior approaches and put the innovations of Zero Bubble PP in context.

My annotated versions of these papers can be found be found on my Github [here](https://github.com/danielvegamyhre/ml-scalability-and-performance-reading-group/tree/main/session_6).


Papers:
1. GPipe: Easy Scaling with Micro-Batch Pipeline Parallelism (https://arxiv.org/abs/1811.06965)
2. PipeDream: Fast and Efficient Pipeline Parallel DNN Training (https://arxiv.org/abs/1806.03377)
3. Zero Bubble Pipeline Parallelism (https://arxiv.org/abs/2401.10241)

Recording:

[![ML Scalability & Performance Reading Group Session 6: Zero Bubble Pipeline Parallelism](https://youtu.be/4wTuGkiob7o?si=xX6gHpgnvSKmJgCE/maxresdefault.jpg)](https://youtu.be/4wTuGkiob7o?si=xX6gHpgnvSKmJgCE)
